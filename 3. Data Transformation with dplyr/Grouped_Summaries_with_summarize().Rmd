---
title: "Grouped Summaries with summarize()"
author: "Pritpal Singh"
date: "2023-9-12"
note: "open this file in RStudio"
---

```{r}
library(tidyverse)
library(ggplot2)
library(nycflights13)
```

The last key verb is `summarize()`. It collapses a data frame to single row.

```{r}
summarize(flights, 
          delay = mean(dep_delay, na.rm = TRUE))
```

`summarize()` is not terribly useful unless we pair it with `group_by()`. This changes the unit of analysis from the complete dataset to individual groups. Then, when we use the **dplyr** verbs a grouped data frame they will be automatically applied "by group". For example if we applied exactly the same code to a data frame grouped by date, we get the average delay per date:

```{r}
by_day <- group_by(flights, year, month, day)
summarize(by_day, delay = mean(dep_delay, na.rm = TRUE), .groups = 'drop')
```

Together `group_by()` and `summarize()` provide one of the tools that we will use most commonly when working with dplyr: grouped summaries. But before we go any further with this, we need to introduce a powerful new idea: the pipe.

### Combining Multiple Operation with the Pipe

Imagine that we want to explore the relationship between the distance and average delay for each location. Using what we know about **dplyr**, we might write code like this

```{r}
by_dest <- group_by(flights, dest)
delay <- summarize(by_dest,
                   count = n(),
                   dist = mean(distance, na.rm = TRUE),
                   delay = mean(arr_delay, na.rm = TRUE))
delay <- filter(delay, count > 20, dest != "HNL")
delay
```

It looks like delay increase with distance up to \~750 miles and then decrease. May be as flights get longer there's more ability to make up delays in the air?

```{r}
ggplot(data = delay, mapping = aes(x = dist, y = delay)) +
  geom_point(aes(size = count), alpha = 1/3) + 
  geom_smooth(se = FALSE)
```

There are three steps to prepare this data:

1.  Group flights by destination
2.  Summarize to compute distance, average delay, and the number of flights.
3.  Filter to remove noisy points and Honolulu airport, which is almost twice far as the next closest airport.

This code is a little frustrating to write because we have to give each intermediate data frame a name, even though we do not care about it. Naming things is hard, so this slows down our analysis.

There's another way to tackle the same problem with the pipe, %\>%

```{r}
delay <- flights %>%
  group_by(dest) %>%
  summarise(count = n(),
            dist = mean(distance, na.rm = TRUE),
            delay = mean(arr_delay, na.rm = TRUE)
            ) %>%
  filter(count > 20, dest != 'HNL')

ggplot(data = delay, mapping = aes(x = dist, y = delay)) +
  geom_point(aes(size = count), alpha = 1/3) + 
  geom_smooth(se = FALSE)
```

Behind the scenes, `x %>% f(y)` turns into `f(x, y)`, and `x %>% f(y) %>% g(z)` turns into `g(f(x, y), z)`, and so on. You can use the pipe to rewrite multiple operations in a way that you can read left-to-right, top-to-bottom. We'll use piping frequently from now on because it considerably improves the readability of code.

### Missing Values

We may have wondered about the `na.rm` argument we used earlier. What happens if we don't set it?

```{r}
flights %>%
  group_by(year, month, day) %>%
  summarize(mean = mean(dep_delay), .groups = 'drop')
```

We get a lost of missing values! That;s because aggregation function obey the usual rule of missing values; if there's any missing value in the input, the output will a missing value. Fortunately, all aggregation function have an `na.rm` argument, which removes the missing values prior to computation

```{r}
flights %>%
  group_by(year, month, day) %>%
  summarize(mean = mean(dep_delay, na.rm = TRUE), .groups = "drop")
```

In this case, where missing values represent cancelled flights, we could also tackle the problem by first removing the cancelled flights. We will so this dataset so we can reuse it in the next few examples

```{r}
not_cancelled <- flights %>%
  filter(!is.na(dep_delay), !is.na(arr_delay))

not_cancelled %>%
  group_by(year, month, day) %>%
  summarize(mean = mean(dep_delay), .groups = "drop")
```

### Counts

Whenever we do any aggregation, it's always a good idea to include either a count `n()`, or count of non missing values, (`sum(!is.na(x))`). That way we can check that we are not drawing conclusions based on very small amount of data. For example, let's look at the planes that have the highest average delays

```{r}
delays <- not_cancelled %>%
  group_by(tailnum) %>%
  summarize(
    delay = mean(arr_delay)
  )

ggplot(data = delays, mapping = aes(x = delay)) + 
  geom_freqpoly(binwidth = 10)
```

Wow, there are some planes that have an *average* delay of 5 hours (300 minutes).

The story is actually a little more nuanced. We can get more insight if we draw a scatterplot of numbers of flights versus average delay.

```{r}
delays <- not_cancelled %>%
  group_by(tailnum) %>%
  summarize(
    delay = mean(arr_delay, na.rm = TRUE),
    n = n()
  )

ggplot(data = delays, mapping = aes(x = n, y = delay)) + 
  geom_point(alpha = 1/10)
```

```{r}
delays %>%
  filter(n > 25) %>%
  ggplot(mapping = aes(x = n, y = delay)) + 
  geom_point(alpha = 1/10)
```

There's another common variation of this type of pattern. Let's look at how the average performance of batters in baseball is related to the number of times they're at bat. Here I use data from the **Lahman** package to compute the batting average (number of hits / number of attempts) of every major league baseball player.

When I plot the skill of the batter (measured by the batting average, `ba`) against the number of opportunities to hit the ball (measured by at bat, `ab`), you see two patterns:

-   As above, the variation in our aggregate decreases as we get more data points.

-   There's a positive correlation between skill (`ba`) and opportunities to hit the ball (`ab`). This is because teams control who gets to play, and obviously they'll pick their best players:

```{r}
# install.packages("Lahman")
```

```{r}
#convert to a tible so it prints nicely

batting <- as_tibble(Lahman :: Batting)

batters <- batting %>%
  group_by(playerID) %>%
  summarize(
    ba = sum(H, na.rm = TRUE) / sum(AB, na.rn = TRUE),
    ab = sum(AB, na.rm = TRUE)
  )

batters %>%
  filter(ab > 100) %>%
  ggplot(mapping = aes(x = ab, y = ba)) + 
  geom_point() + 
  geom_smooth(se = FALSE)
```

This is also has important implications for ranking. if we naively sort on `desc(ba)`, the people withe best batting averages are clearly lucky, not skilled.

```{r}
batters %>%
  arrange(desc(ba))
```

### Useful Summary Functions

Just using means, counts and sum can get us a long way, but R provides many other useful summary functions

*Measuring of location*

We have used `mean(x)` , but `median(x)` is also useful. The mean is the sum divided by the length; the media is a value where 50% of `x` is above it, and 50% is below it.

It's sometime useful to combine aggregation with the logical subsetting.

```{r}
not_cancelled %>%
  group_by(year, month, day) %>%
  summarize(
    #average delay
    avg_delay1 = mean(arr_delay),
    #average positive delay:
    avg_delay = mean(arr_delay[arr_delay > 0]),
    .groups = "drop"
  )
```

*Measures of spread `sd(x), IQR(x), mad(x)`* The mean squared deviation, or standard deviation or sd for short, is the standard measure of spread. The interquartile range `IQR()` and median absolute deviation `mad(x)` are robust equivalents that may be more useful if you have outliers:

```{r}
#why is distance to some destinations more variable than to others?
not_cancelled %>%
  group_by(dest) %>%
  summarise(distance_sd = sd(distance)) %>%
  arrange(desc(distance_sd))
```

*Measures of rank `min(x), quantile(x, 0.25), max(x)`*

Quantiles are a generalization of the median. For example, `quantile(x, 0.25)` will find a value of `x` that is greater than 25% of the values, and less than the remaining 75%

```{r}
#when do the first and last flights leave each day?
not_cancelled %>%
  group_by(year, month, day) %>%
  summarize(
    first = min(dep_time),
    last = max(dep_time),
    .groups = "drop"
  )
```

*Measures of position `first(x), nth(x, 2), last(x)`*

These work similarly to `x[1]`, `x[2]`, and `x[length(x)]` but let you set a default value if that position does not exist (i.e., you're trying to get the third element from a group that only has two elements). For example, we can find the first and last departure for each day

```{r}
not_cancelled %>%
  group_by(year, month, day) %>%
  summarize(
    first_dep = first(dep_time),
    last_dep = last(dep_time),
    .groups = "drop"
  )
```

These functions are complementary to filtering on ranks. Filtering gives you all variables, with each observation in a separate row

```{r}
not_cancelled %>%
  group_by(year, month, day) %>%
  mutate(r = min_rank(desc(dep_time))) %>%
  filter(r %in% range(r))
```

*Counts*

We have seen `n()`, which takes no arguments, and return the size of the current group. To count the number of non-missing values, use `sum(!is.na(x))`. To count the number of distinct (unique) values, use `n_distinct(x)`

```{r}
#which destinations have the most carriers?
not_cancelled %>%
  group_by(dest) %>%
  summarize(carriers = n_distinct(carrier)) %>%
  arrange(desc(carriers))
```

Counts are so useful that **dplyr** provides a simple helper if all we want is a count.

```{r}
not_cancelled %>%
  count(dest)
```

We can optionally provide a weight variable. For example, we could use this to "count" (sum) the total number of miles a plane flew

```{r}
not_cancelled %>%
  count(tailnum, wt = distance)
```

*Counts and proportions of logical values `sum(x > 10), mean(y == 0)`*

When used with numeric functions, `TRUE` is converted to `1` and `FALSE` to `0`. This makes `sum()` and `mean()` very useful: `sum(x)` gives the number of `TRUEs` in `x`, and `mean(x)` gives the proportion

```{r}
# How many flights left before 5am? (these usually indicate delayed flights from the previous day)
not_cancelled %>%
  group_by(year, month, day) %>%
  summarise(n_early = sum(dep_time < 500),
            .groups = "drop")
```

```{r}
#what propotion of lights are delayed by more than an hour?

not_cancelled %>%
  group_by(year, month, day) %>%
  summarize(hour_perc = mean(arr_delay > 60),
            .groups = "keep")
```

### Grouping by Multiple Variables

When we group by multiple variables, each summary peels off one level of the grouping. That makes it easy to progressively roll up a dataset.

```{r message=FALSE}
daily <- group_by(flights, year, month, day)
(per_day <- summarise(daily, flights = n()))
```

```{r message=FALSE, warning=FALSE}
(per_month <- summarise(per_day, flights = sum(flights)))
```

```{r}
(per_year <- summarise(per_month, flights = sum(flights)))
```

Be careful when progressively rolling up summaries: it's OK for sums and counts, but you need to think about weighting means and variances, and it's not possible to do it exactly for rank-based statistics like the median. In other words, the sum of groupwise sums is the overall sum, but the median of groupwise medians is not the overall median.

### Ungrouping

If we need to remove grouping, and return to operations on ungrouped data, use `ungroup()`:

```{r}
daily %>%
  ungroup() %>%
  summarise(flights = n())
```

### Exercise

1.  Brainstorm at least five different ways to assess the typical delay characteristics of a group of flights. Consider the following scenarios:

-   A flight is 15 minutes early 50% of the time, and 15 minutes late 50% of the time.

-   A flight is always 10 minutes late.

-   A flight is 30 minutes early 50% of the time, and 30 minutes late 50% of the time.

-   99% of the time a flight is on time. 1% of the time it's 2 hours late.

    Which is more important: arrival delay or departure delay?

2.  Come up with another approach that will give you the same output as `not_cancelled %>% count(dest)` and `not_cancelled %>% count(tailnum, wt = distance)` (without using `count()`).

3.  Our definition of cancelled flights (`is.na(dep_delay) | is.na(arr_delay)`) is slightly sub-optimal. Why? Which is the most important column?

4.  Look at the number of cancelled flights per day. Is there a pat‐ tern? Is the proportion of cancelled flights related to the average delay?

5.  Which carrier has the worst delays? Challenge: can you disentangle the effects of bad airports versus bad carriers? Why/why not? (Hint: think about `flights %>% group_by(carrier, dest) %>% summarize(n())`.)

6.  For each plane, count the number of flights before the first delay of greater than 1 hour.

7.  What does the sort argument to `count()` do? When might you use it? Exercise 5.6.1

**TODO**: Please complete the exercise on your own.

**1**

> Brainstorm at least 5 different ways to assess the typical delay characteristics of a group of flights. Consider the following scenarios:
>
> -   A flight is 15 minutes early 50% of the time, and 15 minutes late 50% of the time.
>
> -   A flight is always 10 minutes late.
>
> -   A flight is 30 minutes early 50% of the time, and 30 minutes late 50% of the time.
>
> -   99% of the time a flight is on time. 1% of the time it\'s 2 hours late.
>
> Which is more important: arrival delay or departure delay?

What this question gets at is a fundamental question of data analysis: the cost function. As analysts, the reason we are interested in flight delay because it is costly to passengers. But it is worth thinking carefully about how it is costly and use that information in ranking and measuring these scenarios.

In many scenarios, arrival delay is more important. In most cases, being arriving late is more costly to the passenger since it could disrupt the next stages of their travel, such as connecting flights or scheduled meetings.\
If a departure is delayed without affecting the arrival time, this delay will not have those affects plans nor does it affect the total time spent traveling. This delay could be beneficial, if less time is spent in the cramped confines of the airplane itself, or a negative, if that delayed time is still spent in the cramped confines of the airplane on the runway.

Variation in arrival time is worse than consistency. If a flight is always 30 minutes late and that delay is known, then it is as if the arrival time is that delayed time. The traveler could easily plan for this. But higher variation in flight times makes it harder to plan.

**2**

> Come up with another approach that will give you the same output as `not_cancelled %>% count(dest)` and `not_cancelled %>% count(tailnum, wt = distance)` (without using `count()`).

```{r}
not_cancelled <- flights %>%
  filter(!is.na(dep_delay), !is.na(arr_delay))
```

The first expression is the following.

```{r}
not_cancelled %>% 
  count(dest)
```

The `count()` function counts the number of instances within each group of variables. Instead of using the `count()` function, we can combine the `group_by()` and `summarise()` verbs.

```{r}
not_cancelled %>%
  group_by(dest) %>%
  summarise(n = length(dest))
```

An alternative method for getting the number of observations in a data frame is the function `n()`.

```{r}
not_cancelled %>%
  group_by(dest) %>%
  summarise(n = n())
```

Another alternative to `count()` is to use `group_by()` followed by `tally()`. In fact, `count()` is effectively a short-cut for `group_by()` followed by `tally()`.

```{r}
not_cancelled %>%
  group_by(tailnum) %>%
  tally()
```

The second expression also uses the `count()` function, but adds a `wt` argument.

```{r}
not_cancelled %>% 
  count(tailnum, wt = distance)
```

As before, we can replicate `count()` by combining the `group_by()` and `summarise()` verbs. But this time instead of using `length()`, we will use `sum()` with the weighting variable.

```{r}
not_cancelled %>%
  group_by(tailnum) %>%
  summarise(n = sum(distance))
```

Like the previous example, we can also use the combination `group_by()` and `tally()`. Any arguments to `tally()` are summed.

```{r}
not_cancelled %>%
  group_by(tailnum) %>%
  tally(distance)
```

**3**

> Our definition of cancelled flights `(is.na(dep_delay) | is.na(arr_delay))` is slightly suboptimal. Why? Which is the most important column?

If a flight never departs, then it won\'t arrive. A flight could also depart and not arrive if it crashes, or if it is redirected and lands in an airport other than its intended destination. So the most important column is `arr_delay`, which indicates the amount of delay in arrival.

```{r}
filter(flights, !is.na(dep_delay), is.na(arr_delay)) %>%
  select(dep_time, arr_time, sched_arr_time, dep_delay, arr_delay)
```

In this data `dep_time` can be non-missing and `arr_delay` missing but `arr_time` not missing. Some further [research](https://hyp.is/TsdRpofJEeqzs6-vUOfVBg/jrnold.github.io/r4ds-exercise-solutions/transform.html) found that these rows correspond to diverted flights. The [BTS](https://www.transtats.bts.gov/DL_SelectFields.asp?Table_ID=236) database that is the source for the `flights` table contains additional information for diverted flights that is not included in the nycflights13 data. The source contains a column `DivArrDelay` with the description:

> Difference in minutes between scheduled and actual arrival time for a diverted flight reaching scheduled destination. The `ArrDelay` column remains `NULL` for all diverted flights

**4**

> Look at the number of cancelled flights per day. Is there a pattern? Is the proportion of cancelled flights related to the average delay?

One pattern in cancelled flights per day is that the number of cancelled flights increases with the total number of flights per day. The proportion of cancelled flights increases with the average delay of flights.

The relationship `!(is.na(arr_delay) & is.na(dep_delay))` is equal to `!is.na(arr_delay) | !is.na(dep_delay)` by [De Morgan\'s law](https://en.wikipedia.org/wiki/De_Morgan%27s_laws).

The first part of the question asks for any pattern in the number of cancelled flights per day. I\'ll look at the relationship between the number of cancelled flights per day and the total number of flights in a day. There should be an increasing relationship for two reasons. First, if all flights are equally likely to be cancelled, then days with more flights should have a higher number of cancellations. Second, it is likely that days with more flights would have a higher probability of cancellations because congestion itself can cause delays and any delay would affect more flights, and large delays can lead to cancellations.

```{r}
cancelled_per_day <- 
  flights %>%
  mutate(cancelled = (is.na(arr_delay) | is.na(dep_delay))) %>%
  group_by(year, month, day) %>%
  summarise(
    cancelled_num = sum(cancelled),
    flights_num = n(),
    .groups = "keep"
  )
```

Plotting `flights_num` against `cancelled_num` shows that the number of flights cancelled increases with the total number of flights.

```{r}
ggplot(cancelled_per_day) +
  geom_point(aes(x = flights_num, y = cancelled_num)) 
```

The second part of the question asks whether there is a relationship between the proportion of flights cancelled and the average departure delay. I implied this in my answer to the first part of the question, when I noted that increasing delays could result in increased cancellations. The question does not specify which delay, so I will show the relationship for both.

```{r}
cancelled_and_delays <- 
  flights %>%
  mutate(cancelled = (is.na(arr_delay) | is.na(dep_delay))) %>%
  group_by(year, month, day) %>%
  summarise(
    cancelled_prop = mean(cancelled),
    avg_dep_delay = mean(dep_delay, na.rm = TRUE),
    avg_arr_delay = mean(arr_delay, na.rm = TRUE),
    .groups = "drop"
  )
  
```

There is a strong increasing relationship between both average departure delay and average arrival delay and the proportion of cancelled flights.

```{r}
ggplot(cancelled_and_delays) +
  geom_point(aes(x = avg_dep_delay, y = cancelled_prop))
```

```{r}
ggplot(cancelled_and_delays) +
  geom_point(aes(x = avg_arr_delay, y = cancelled_prop))
```

**5**

> Which carrier has the worst delays? Challenge: can you disentangle the effects of bad airports vs. bad carriers? Why/why not? (Hint: think about `flights %>% group_by(carrier, dest) %>% summarise(n())`)

```{r}
flights %>%
  group_by(carrier) %>%
  summarise(arr_delay = mean(arr_delay, na.rm = TRUE)) %>%
  arrange(desc(arr_delay))
```

What airline corresponds to the `"F9"` carrier code?

```{r}
filter(airlines, carrier == "F9")
```

You can get part of the way to disentangling the effects of airports versus bad carriers by comparing the average delay of each carrier to the average delay of flights within a route (flights from the same origin to the same destination). Comparing delays between carriers and within each route disentangles the effect of carriers and airports. A better analysis would compare the average delay of a carrier\'s flights to the average delay of *all other* carrier\'s flights within a route.

```{r message=FALSE, warning=FALSE}
flights %>%
  filter(!is.na(arr_delay)) %>%
  # Total delay by carrier within each origin, dest
  group_by(origin, dest, carrier) %>%
  summarise(
    arr_delay = sum(arr_delay),
    flights = n()
  ) %>%
  # Total delay within each origin dest
  group_by(origin, dest) %>%
  mutate(
    arr_delay_total = sum(arr_delay),
    flights_total = sum(flights)
  ) %>%
  # average delay of each carrier - average delay of other carriers
  ungroup() %>%
  mutate(
    arr_delay_others = (arr_delay_total - arr_delay) /
      (flights_total - flights),
    arr_delay_mean = arr_delay / flights,
    arr_delay_diff = arr_delay_mean - arr_delay_others
  ) %>%
  # remove NaN values (when there is only one carrier)
  filter(is.finite(arr_delay_diff)) %>%
  # average over all airports it flies to
  group_by(carrier) %>%
  summarise(arr_delay_diff = mean(arr_delay_diff)) %>%
  arrange(desc(arr_delay_diff))
```

There are more sophisticated ways to do this analysis, however comparing the delay of flights within each route goes a long ways toward disentangling airport and carrier effects. To see a more complete example of this analysis, see this FiveThirtyEight [piece](https://fivethirtyeight.com/features/the-best-and-worst-airlines-airports-and-flights-summer-2015-update/).

**6**

> What does the sort argument to `count()` do? When might you use it?

The sort argument to `count()` sorts the results in order of `n`. You could use this anytime you would run `count()` followed by `arrange()`.

For example, the following expression counts the number of flights to a destination and sorts the returned data from highest to lowest.

```{r}
flights %>%
  count(dest, sort = TRUE)
```
