---
title: "Add New Variables with mutate()"
author: "Pritpal Singh"
date: "2023-9-12"
note: "open this file in RStudio"
---

Besides selecting sets of existing columns, it's often useful to add new columns that are functions of existing columns.

```{r}
library(tidyverse)
library(nycflights13)
```

`mutate()` always adds new columns at the end of our dataset.

```{r}
flights_sml <- select(flights, year:day, ends_with("delay"), distance, air_time)
flights_sml
```

```{r}
mutate(flights_sml, 
       gain = arr_delay - dep_delay,
       speed = distance / air_time * 60)
```

Note that we can refer to columns that we have just created

```{r}
mutate(flights_sml,
       gain = arr_delay - dep_delay,
       hours = air_time / 60,
       gain_per_hour = gain / hours)
```

If we only want to keep the new variables, use `transmute()`

```{r}
transmute(flights, 
          gain = arr_delay - dep_delay,
          hours = air_time / 60,
          gain_per_hour = gain / hours
          )
```

### Useful Creation Functions

There are many function for creating new variables that we can use with `mutate()`. The key property is that the function must be vectorized; it must take a vector of values as input, and return a vector with the same number of values as output.

**Arithmetic Operators +, -, *, /, \^***

Arithmetic operators are also useful in conjunction with the aggregate functions. For example, `x / sum(x)` calculates the proportion of a total, and `y - mean(y)` computes the difference from the mean.

**Modular Arithmetic (%/% and %%)**

`%/%` (integer division) and `%%` (remainder), where `x == y * (x %/% y) + (x %% y)`. Modular arithmetic is a handy tool because it allows us to break integers into pieces. For example, in the flights dataset, we can compute `hour` and `minute` from `dep_time` with:

```{r}
transmute(flights,
          dep_time,
          hour = dep_time %/% 100,
          minute = dep_time %% 100
          )
```

**Logs** `log(), log2(), log10()`

Logarithms are an incredibly useful transformation for dealing with data that ranges across multiple orders of magnitude. They also convert multiplication relationships to additive a feature.

**Offsets**

`lead()` and `lag()` allow us to refer to leading or lagging values. This allows us to compute running differences (e.g., `x - lag(x))` or find when values change `(x != lag(x))`. They are mist useful in conjunction with `group_by()`.

```{r}
(x <- 1:10)
```

```{r}
lag(x)
```

```{r}
lead(x)
```

**Cumulative and rolling aggregates**

R provides functions for running sums, products, mins and maxes: `cumsum(), cumprod(), cummin(), cummax()`; and **dplyr** provides `cummean()` for cumulative means. If we need rolling aggregates, try **RcppRoll** packages.

```{r}
x
```

```{r}
cumsum(x)
```

```{r}
cummean(x)
```

**Logical Comparisons \<, \<=, \>, \>=, !=**

**Ranking**

There a number of ranking functions, but we should start with `min_rank()`. It does the most usual type of ranking. The default gives the smallest values the smallest ranks, use `desc(x)` to give the largest values the largest ranks.

```{r}
y <- c(1, 2, 2, NA, 3, 4)
min_rank(y)
```

```{r}
min_rank(desc(y))
```

If `min_rank()` does not do what we need. look at the variants `row_number(), dense_rank(), cume_dist(),` and `nitle()`. See their help pages for more details.

```{r}
row_number(y)
```

```{r}
dense_rank(y)
```

```{r}
percent_rank(y)
```

```{r}
cume_dist(y)
```

## Exercise

1.  Currently `dep_time` and `sched_dep_time` are convenient to look at, but hard to compute with because they're not really continuous numbers. Convert them to a more convenient representation of number of minutes since midnight.
2.  Compare `air_time` with `arr_time - dep_time`. What do you expect to see? What do you see?What do you need to do to fix it?
3.  Compare `dep_time`, `sched_dep_time`, and `dep_delay`. How would you expect those three numbers to be related?
4.  Find the 10 most delayed flights using a ranking function. How do you want to handle ties? Carefully read the documentation for `min_rank()`.
5.  What does `1:3 + 1:10` return? Why?
6.  What trigonometric functions does R provide?

**TODO**: Please complete the exercise on your own.

## Answer

**1**

> Currently `dep_time` and `sched_dep_time` are convenient to look at, but hard to compute with because they're not really continuous numbers. Convert them to a more convenient representation of number of minutes since midnight.

To get the departure times in the number of minutes, divide `dep_time` by 100 to get the hours since midnight and multiply by 60 and add the remainder of `dep_time` divided by 100. For example, `1504` represents 15:04 (or 3:04 PM), which is 904 minutes after midnight. To generalize this approach, we need a way to split out the hour-digits from the minute-digits. Dividing by 100 and discarding the remainder using the integer division operator, `%/%` gives us the following.

```{r}
1504 %/% 100
```

Instead of `%/%` could also use `/` along with `trunc()` or `floor()`, but `round()` would not work. To get the minutes, instead of discarding the remainder of the division by `100`, we only want the remainder.

```{r}
1504 %% 100
```

Now, we can combine the hours (multiplied by 60 to convert them to minutes) and minutes to get the number of minutes after midnight.

```{r}
1504 %/% 100 * 60 + 1504 %% 100
```

There is one remaining issue. Midnight is represented by `2400`, which would correspond to `1440` minutes since midnight, but it should correspond to `0`. After converting all the times to minutes after midnight, `x %% 1440` will convert `1440` to zero while keeping all the other times the same.

Now we will put it all together. The following code creates a new data frame `flights_times` with columns `dep_time_mins` and `sched_dep_time_mins`. These columns convert `dep_time` and `sched_dep_time`, respectively, to minutes since midnight.

```{r}
flights_times <- mutate(flights,
  dep_time_mins = (dep_time %/% 100 * 60 + dep_time %% 100) %% 1440,
  sched_dep_time_mins = (sched_dep_time %/% 100 * 60 +
    sched_dep_time %% 100) %% 1440
)
# view only relevant columns
select(
  flights_times, dep_time, dep_time_mins, sched_dep_time,
  sched_dep_time_mins
)
```

**2**

> Compare `air_time` with `arr_time - dep_time`. What do you expect to see? What do you see? What do you need to do to fix it?

I expect that `air_time` is the difference between the arrival (`arr_time`) and departure times (`dep_time`). In other words, `air_time = arr_time - dep_time`.

```{r}
flights_airtime <-
  mutate(flights,
    dep_time = (dep_time %/% 100 * 60 + dep_time %% 100) %% 1440,
    arr_time = (arr_time %/% 100 * 60 + arr_time %% 100) %% 1440,
    air_time_diff = air_time - arr_time + dep_time
  )
```

So, does `air_time = arr_time - dep_time`? If so, there should be no flights with non-zero values of `air_time_diff`.

```{r}
nrow(filter(flights_airtime, air_time_diff != 0))
```

It turns out that there are many flights for which `air_time != arr_time - dep_time`. Other than data errors, I can think of two reasons why `air_time` would not equal `arr_time - dep_time`.

1.  The flight passes midnight, so `arr_time < dep_time`. In these cases, the difference in airtime should be by 24 hours (1,440 minutes).

2.  The flight crosses time zones, and the total air time will be off by hours (multiples of 60). All flights in `flights` departed from New York City and are domestic flights in the US. This means that flights will all be to the same or more westerly time zones. Given the time-zones in the US, the differences due to time-zone should be 60 minutes (Central) 120 minutes (Mountain), 180 minutes (Pacific), 240 minutes (Alaska), or 300 minutes (Hawaii).

Both of these explanations have clear patterns that I would expect to see if they were true. In particular, in both cases, since time-zones and crossing midnight only affects the hour part of the time, all values of `air_time_diff` should be divisible by 60. I'll visually check this hypothesis by plotting the distribution of `air_time_diff`. If those two explanations are correct, distribution of `air_time_diff` should comprise only spikes at multiples of 60.

```{r}
library(ggplot2)

ggplot(flights_airtime, aes(x = air_time_diff)) +
  geom_histogram(binwidth = 1)
```

This is not the case. While, the distribution of `air_time_diff` has modes at multiples of 60 as hypothesized, it shows that there are many flights in which the difference between air time and local arrival and departure times is not divisible by 60.

Let's also look at flights with Los Angeles as a destination. The discrepancy should be 180 minutes.

```{r}
ggplot(filter(flights_airtime, dest == "LAX"), aes(x = air_time_diff)) +
  geom_histogram(binwidth = 1)
```

To fix these time-zone issues, I would want to convert all the times to a date-time to handle overnight flights, and from local time to a common time zone, most likely [UTC](https://en.wikipedia.org/wiki/Coordinated_Universal_Time), to handle flights crossing time-zones. The `tzone` column of `nycflights13::airports` gives the time-zone of each airport. See the ["Dates and Times"](https://r4ds.had.co.nz/dates-and-times.html) for an introduction on working with date and time data.

**3**

> Compare `dep_time`, `sched_dep_time`, and `dep_delay`. How would you expect those three numbers to be related?

I would expect the departure delay (`dep_delay`) to be equal to the difference between scheduled departure time (`sched_dep_time`), and actual departure time (`dep_time`), `dep_time - sched_dep_time = dep_delay`.

As with the previous question, the first step is to convert all times to the number of minutes since midnight. The column, `dep_delay_diff`, is the difference between the column, `dep_delay`, and departure delay calculated directly from the scheduled and actual departure times.

```{r}
flights_deptime <-
  mutate(flights,
    dep_time_min = (dep_time %/% 100 * 60 + dep_time %% 100) %% 1440,
    sched_dep_time_min = (sched_dep_time %/% 100 * 60 +
      sched_dep_time %% 100) %% 1440,
    dep_delay_diff = dep_delay - dep_time_min + sched_dep_time_min
  )
```

Does `dep_delay_diff` equal zero for all rows?

```{r}
filter(flights_deptime, dep_delay_diff != 0)
```

No. Unlike the last question, time zones are not an issue since we are only considering departure times. However, the discrepancies could be because a flight was scheduled to depart before midnight, but was delayed after midnight. All of these discrepancies are exactly equal to 1440 (24 hours), and the flights with these discrepancies were scheduled to depart later in the day.

```{r}
ggplot(
  filter(flights_deptime, dep_delay_diff > 0),
  aes(y = sched_dep_time_min, x = dep_delay_diff)
) +
  geom_point()
```

Thus the only cases in which the departure delay is not equal to the difference in scheduled departure and actual departure times is due to a quirk in how these columns were stored.

**4**

> Find the 10 most delayed flights using a ranking function. How do you want to handle ties? Carefully read the documentation for `min_rank()`.

The **dplyr** package provides multiple functions for ranking, which differ in how they handle tied values: `row_number()`, `min_rank()`, `dense_rank()`. To see how they work, let's create a data frame with duplicate values in a vector and see how ranking functions handle ties.

```{r}
rankme <- tibble(
  x = c(10, 5, 1, 5, 5)
)
```

```{r}
rankme <- mutate(rankme,
  x_row_number = row_number(x),
  x_min_rank = min_rank(x),
  x_dense_rank = dense_rank(x)
)
arrange(rankme, x)
```

The function `row_number()` assigns each element a unique value. The result is equivalent to the index (or row) number of each element after sorting the vector, hence its name.

The`min_rank()` and `dense_rank()` assign tied values the same rank, but differ in how they assign values to the next rank. For each set of tied values the `min_rank()` function assigns a rank equal to the number of values less than that tied value plus one. In contrast, the `dense_rank()` function assigns a rank equal to the number of distinct values less than that tied value plus one. To see the difference between `dense_rank()` and `min_rank()` compare the value of `rankme$x_min_rank` and `rankme$x_dense_rank` for `x = 10`.

If I had to choose one for presenting rankings to someone else, I would use `min_rank()` since its results correspond to the most common usage of rankings in sports or other competitions. In the code below, I use all three functions, but since there are no ties in the top 10 flights, the results don't differ.

```{r}
flights_delayed <- mutate(flights, 
                          dep_delay_min_rank = min_rank(desc(dep_delay)),
                          dep_delay_row_number = row_number(desc(dep_delay)),
                          dep_delay_dense_rank = dense_rank(desc(dep_delay))
                          )
flights_delayed <- filter(flights_delayed, 
                          !(dep_delay_min_rank > 10 | dep_delay_row_number > 10 | dep_delay_dense_rank > 10))

flights_delayed <- arrange(flights_delayed, dep_delay_min_rank)

print(select(flights_delayed, month, day, carrier, flight, dep_delay, 
             dep_delay_min_rank, dep_delay_row_number, dep_delay_dense_rank),
      n = Inf)
```

In addition to the functions covered here, the `rank()` function provides several more ways of ranking elements.

There are other ways to solve this problem that do not using ranking functions. To select the top 10, sort values with `arrange()` and select the top values with `slice`:

```{r}
flights_delayed2 <- arrange(flights, desc(dep_delay))
flights_delayed2 <- slice(flights_delayed2, 1:10)
select(flights_delayed2,  month, day, carrier, flight, dep_delay)
```

Alternatively, we could use the `top_n()`

```{r}
flights_delayed3 <- top_n(flights, 10, dep_delay)
flights_delayed3 <- arrange(flights_delayed3, desc(dep_delay))
select(flights_delayed3, month, day, carrier, flight, dep_delay)
```

The previous two approaches will always select 10 rows even if there are tied values. Ranking functions provide more control over how tied values are handled. Those approaches will provide the 10 rows with the largest values of `dep_delay`, while ranking functions can provide all rows with the 10 largest values of `dep_delay`. If there are no ties, these approaches are equivalent. If there are ties, then which is more appropriate depends on the use.

**5**

> What does `1:3 + 1:10` return? Why?

```{r}
1:3 + 1:10
```

This is equivalent to the following.

```{r}
c(1 + 1, 2 + 2, 3 + 3, 1 + 4, 2 + 5, 3 + 6, 1 + 7, 2 + 8, 3 + 9, 1 + 10)
```

When adding two vectors, R recycles the shorter vector's values to create a vector of the same length as the longer vector. The code also raises a warning that the shorter vector is not a multiple of the longer vector. A warning is raised since when this occurs, it is often unintended and may be a bug.

**6**

> What trigonometric functions does R provide?

All trigonometric functions are all described in a single help page, named `Trig`. You can open the documentation for these functions with `?Trig` or by using `?` with any of the following functions, for example:`?sin`.

R provides functions for the three primary trigonometric functions: sine (`sin()`), cosine (`cos()`), and tangent (`tan()`). The input angles to all these functions are in [radians](https://en.wikipedia.org/wiki/Radian).

```{r}
x <- seq(-3, 7, by = 1 / 2)
sin(base :: pi * x)
```

```{r}
cos(base :: pi * x)
```

```{r}
tan(base :: pi * x)
```

```{r}
pi
```

R provides the `pi` variable, there is nothing preventing a user from changing its value. For example, I could redefine `pi` to [3.14](https://en.wikipedia.org/wiki/Indiana_Pi_Bill) or any other value.

```{r}
pi <- 3.14
pi
```

```{r}
pi <- "Apple"
pi
```

For that reason, if you are using the builtin `pi` variable in computations and are paranoid, you may want to always reference it as `base::pi`.

```{r}
base :: pi
```

In the previous code block, since the angles were in radians, I wrote them as `pi` times some number. Since it is often easier to write radians multiple of `pi` R provides some convenience functions that do that. The function `sinpi(x)`, is equivalent to `sin(pi * x)`. The functions `cospi()` and `tanpi()` are similarly defined for the sin and tan functions, respectively.

```{r}
sinpi(x)
```

```{r}
cospi(x)
```

```{r}
tanpi(x)
```

R provides the function arc-cosine (`acos()`), arc-sine (`asin()`), and arc-tangent (`atan()`).

```{r}
x <- seq(-1, 1, by = 1 / 4)
acos(x)
```

```{r}
asin(x)
```

```{r}
atan(x)
```

Finally, R provides the function `atan2()`. Calling `atan2(y, x)` returns the angle between the x-axis and the vector from `(0,0)` to `(x, y)`.

```{r}
atan2(c(1, 0, -1, 0), c(0, 1, 0, -1))
```
